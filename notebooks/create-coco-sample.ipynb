{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='coco2017-sample'\n",
    "dataType='train2017'\n",
    "annFile='{}/annotations/instances_{}.json'.format(dataDir,dataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(annFile)\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['info', 'licenses', 'images', 'annotations', 'categories'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['segmentation', 'area', 'iscrowd', 'image_id', 'bbox', 'category_id', 'id'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['annotations'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26035\n",
      "{'license': 2, 'file_name': '000000000074.jpg', 'coco_url': 'http://images.cocodataset.org/train2017/000000000074.jpg', 'height': 426, 'width': 640, 'date_captured': '2013-11-15 03:08:44', 'flickr_url': 'http://farm5.staticflickr.com/4087/5078192399_aaefdb5074_z.jpg', 'id': 74}\n",
      "91250\n",
      "{'license': 3, 'file_name': '000000000036.jpg', 'coco_url': 'http://images.cocodataset.org/train2017/000000000036.jpg', 'height': 640, 'width': 481, 'date_captured': '2013-11-18 06:56:10', 'flickr_url': 'http://farm8.staticflickr.com/7216/7200825264_af0f941e1a_z.jpg', 'id': 36}\n"
     ]
    }
   ],
   "source": [
    "new_imgs = []\n",
    "for i in range(len(data['images'])):\n",
    "    if data['images'][i]['file_name'] == '000000000036.jpg' or data['images'][i]['file_name'] == '000000000074.jpg':\n",
    "        print(i)\n",
    "        print(data['images'][i])\n",
    "        new_imgs.append(data['images'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['images'] = new_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "{'segmentation': [[321.02, 321.0, 314.25, 307.99, 307.49, 293.94, 300.2, 286.14, 290.84, 277.81, 285.11, 276.25, 267.94, 277.81, 256.49, 279.89, 244.52, 281.97, 227.35, 287.18, 192.49, 290.3, 168.55, 289.26, 142.53, 287.18, 121.72, 293.42, 105.07, 303.83, 94.14, 313.2, 86.33, 326.73, 84.25, 339.22, 76.97, 343.9, 67.6, 345.46, 61.87, 350.66, 69.16, 360.03, 77.49, 360.03, 93.62, 358.99, 105.07, 356.91, 110.27, 351.7, 117.55, 353.79, 121.2, 352.74, 132.64, 361.07, 139.41, 367.32, 145.89, 373.77, 156.05, 374.5, 160.41, 370.14, 167.67, 367.96, 168.39, 370.87, 169.84, 362.88, 166.94, 356.35, 177.83, 353.45, 190.89, 353.45, 209.54, 358.32, 224.96, 360.09, 240.82, 361.85, 258.45, 364.49, 267.43, 374.29, 275.14, 377.71, 293.14, 379.43, 300.86, 370.86, 303.43, 358.86, 312.0, 356.29, 326.57, 361.43, 341.14, 365.71, 344.57, 369.14, 358.29, 370.86, 358.29, 364.0, 355.71, 360.57, 342.86, 348.57, 334.29, 340.0, 320.57, 322.86]], 'area': 18234.62355, 'iscrowd': 0, 'image_id': 74, 'bbox': [61.87, 276.25, 296.42, 103.18], 'category_id': 18, 'id': 1774}\n",
      "2367\n",
      "{'segmentation': [[10.08, 50.39, 18.32, 48.55, 32.98, 44.89, 50.39, 24.74, 57.72, 9.16, 74.21, 4.58, 87.03, 3.66, 74.21, 21.07, 58.63, 34.81, 56.8, 41.23, 55.88, 44.89, 65.96, 54.05, 74.21, 104.44, 72.37, 115.43, 80.62, 120.93, 92.53, 129.17, 101.69, 138.34, 115.43, 144.75, 131.92, 160.32, 156.66, 190.55, 162.15, 207.05, 162.15, 213.46, 162.15, 268.43, 150.25, 287.66, 110.85, 296.83, 98.94, 310.57, 87.03, 316.06, 49.47, 306.9, 6.41, 259.26, 2.75, 164.9, 19.24, 142.92, 28.4, 135.59, 28.4, 131.01, 28.4, 126.43, 4.58, 138.34, 4.58, 68.71, 2.75, 57.72]], 'area': 30078.494700000003, 'iscrowd': 0, 'image_id': 74, 'bbox': [2.75, 3.66, 159.4, 312.4], 'category_id': 2, 'id': 128367}\n",
      "4072\n",
      "{'segmentation': [[301.32, 93.96, 305.72, 94.51, 306.54, 95.06, 307.09, 99.18, 307.92, 102.48, 311.22, 105.78, 312.04, 109.35, 313.42, 118.97, 313.97, 123.1, 309.57, 127.49, 308.19, 130.79, 307.64, 136.29, 307.09, 144.26, 306.82, 151.96, 303.52, 152.79, 297.75, 133.82, 296.92, 128.59, 296.1, 122.55, 295.55, 115.67, 296.92, 108.25, 297.75, 106.33, 299.95, 103.58, 300.77, 101.1, 299.4, 96.7, 299.67, 94.51]], 'area': 638.7158, 'iscrowd': 0, 'image_id': 74, 'bbox': [295.55, 93.96, 18.42, 58.83], 'category_id': 1, 'id': 195946}\n",
      "5298\n",
      "{'segmentation': [[335.81, 122.31, 329.12, 117.12, 326.94, 112.44, 329.12, 106.92, 332.8, 102.74, 331.8, 97.72, 333.64, 97.05, 335.14, 102.23, 340.49, 112.77, 338.49, 119.63, 336.31, 122.98]], 'area': 180.8609499999999, 'iscrowd': 0, 'image_id': 74, 'bbox': [326.94, 97.05, 13.55, 25.93], 'category_id': 1, 'id': 253933}\n",
      "14623\n",
      "{'segmentation': [[361.86, 147.55, 368.19, 147.0, 368.19, 132.67, 371.5, 125.23, 372.33, 115.31, 372.05, 102.91, 366.54, 95.47, 356.62, 98.78, 358.27, 112.28, 361.58, 124.4, 359.93, 134.05, 358.55, 144.52]], 'area': 562.1028500000001, 'iscrowd': 0, 'image_id': 74, 'bbox': [356.62, 95.47, 15.71, 52.08], 'category_id': 1, 'id': 1225755}\n",
      "21421\n",
      "{'segmentation': [[464.64, 140.47, 463.71, 132.79, 463.71, 127.9, 464.41, 125.8, 467.2, 124.17, 469.77, 124.17, 471.63, 123.48, 477.68, 118.35, 478.15, 116.03, 478.15, 112.54, 481.87, 105.32, 485.13, 105.09, 487.22, 105.09, 489.32, 105.55, 491.65, 107.88, 492.34, 122.54, 493.74, 137.91, 486.53, 138.37, 478.38, 138.14, 475.35, 136.05, 473.96, 140.7, 473.72, 142.8, 473.96, 145.36, 470.93, 146.99, 464.41, 146.52, 462.32, 146.06, 462.08, 145.36]], 'area': 758.6169499999999, 'iscrowd': 0, 'image_id': 74, 'bbox': [462.08, 105.09, 31.66, 41.9], 'category_id': 1, 'id': 1733076}\n",
      "21596\n",
      "{'segmentation': [[282.37, 111.28, 292.44, 128.37, 285.43, 140.2, 286.75, 150.72, 284.12, 149.4, 281.93, 133.19, 277.99, 121.8, 277.11, 111.28, 280.18, 103.84, 284.56, 103.84, 287.19, 110.85]], 'area': 319.6597999999997, 'iscrowd': 0, 'image_id': 74, 'bbox': [277.11, 103.84, 15.33, 46.88], 'category_id': 1, 'id': 1747768}\n",
      "21632\n",
      "{'segmentation': [[286.76, 109.9, 286.55, 104.71, 291.75, 103.41, 293.7, 107.52, 293.48, 110.34, 292.4, 112.5, 290.66, 117.7, 293.26, 123.76, 294.34, 127.66, 290.88, 126.15, 288.28, 121.6, 287.85, 120.3, 286.12, 117.48, 285.47, 115.97, 284.6, 114.67, 282.65, 111.64]], 'area': 131.1144, 'iscrowd': 0, 'image_id': 74, 'bbox': [282.65, 103.41, 11.69, 24.25], 'category_id': 1, 'id': 1751664}\n",
      "351576\n",
      "{'segmentation': [[164.5, 479.38, 120.26, 448.4, 93.7, 442.87, 91.5, 440.65, 36.17, 383.12, 28.43, 384.23, 35.06, 382.02, 4.1, 307.89, 9.62, 297.94, 6.3, 224.92, 0.0, 224.92, 9.62, 219.4, 38.39, 146.38, 52.77, 143.06, 111.4, 88.85, 106.97, 78.89, 119.16, 83.32, 204.34, 61.2, 203.23, 50.12, 208.76, 57.87, 302.8, 70.04, 302.8, 63.4, 306.12, 71.15, 383.55, 120.92, 387.98, 117.62, 383.55, 124.25, 433.34, 193.94, 439.97, 192.83, 433.34, 199.48, 452.14, 274.71, 457.68, 274.71, 451.05, 280.23, 434.45, 355.47, 436.67, 364.33, 428.92, 358.79, 395.72, 404.15, 380.23, 327.81, 362.54, 318.96, 341.52, 310.11, 344.84, 255.9, 344.84, 221.6, 332.67, 200.59, 326.03, 197.26, 318.29, 171.82, 288.42, 160.76, 265.18, 157.44, 245.27, 162.98, 229.78, 171.82, 207.65, 195.05, 203.23, 250.36, 220.94, 295.72, 232.0, 307.89, 232.0, 376.49, 223.14, 375.39, 225.35, 318.96, 194.37, 323.38, 182.21, 338.87, 171.15, 393.09, 191.07, 480.47, 162.3, 480.47], [226.46, 416.32, 220.94, 463.89, 230.89, 468.31, 229.78, 411.89]], 'area': 97486.80810000001, 'iscrowd': 0, 'image_id': 36, 'bbox': [0.0, 50.12, 457.68, 430.35], 'category_id': 28, 'id': 284996}\n",
      "408933\n",
      "{'segmentation': [[345.28, 220.68, 348.17, 269.8, 355.4, 307.36, 377.07, 318.92, 395.85, 370.93, 444.97, 565.96, 473.86, 616.52, 478.19, 628.08, 431.96, 628.08, 401.63, 581.85, 377.07, 477.83, 375.62, 529.84, 387.18, 600.63, 397.29, 628.08, 325.06, 623.75, 216.7, 622.3, 216.7, 606.41, 251.38, 529.84, 223.93, 529.84, 209.48, 528.4, 202.26, 505.28, 193.59, 485.06, 167.58, 375.26, 179.14, 334.81, 203.7, 324.7, 229.71, 313.14, 209.48, 278.47, 193.59, 248.13, 208.04, 188.89, 223.93, 175.89, 236.93, 168.67, 258.6, 162.89, 294.72, 168.67, 310.61, 174.45, 326.5, 197.56]], 'area': 86145.2971, 'iscrowd': 0, 'image_id': 36, 'bbox': [167.58, 162.89, 310.61, 465.19], 'category_id': 1, 'id': 453991}\n"
     ]
    }
   ],
   "source": [
    "new_anns = []\n",
    "for i in range(len(data['annotations'])):\n",
    "    if data['annotations'][i]['image_id'] == 36 or data['annotations'][i]['image_id'] == 74:\n",
    "        print(i)\n",
    "        print(data['annotations'][i])\n",
    "        new_anns.append(data['annotations'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['annotations'] = new_anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newAnnFile='{}/annotations/instances_{}-sample.json'.format(dataDir,dataType)\n",
    "with open(newAnnFile, 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "annFile='{}/annotations/person_keypoints_{}.json'.format(dataDir,dataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(annFile)\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['info', 'licenses', 'images', 'annotations', 'categories'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26035\n",
      "{'license': 2, 'file_name': '000000000074.jpg', 'coco_url': 'http://images.cocodataset.org/train2017/000000000074.jpg', 'height': 426, 'width': 640, 'date_captured': '2013-11-15 03:08:44', 'flickr_url': 'http://farm5.staticflickr.com/4087/5078192399_aaefdb5074_z.jpg', 'id': 74}\n",
      "91250\n",
      "{'license': 3, 'file_name': '000000000036.jpg', 'coco_url': 'http://images.cocodataset.org/train2017/000000000036.jpg', 'height': 640, 'width': 481, 'date_captured': '2013-11-18 06:56:10', 'flickr_url': 'http://farm8.staticflickr.com/7216/7200825264_af0f941e1a_z.jpg', 'id': 36}\n"
     ]
    }
   ],
   "source": [
    "new_imgs = []\n",
    "for i in range(len(data['images'])):\n",
    "    if data['images'][i]['file_name'] == '000000000036.jpg' or data['images'][i]['file_name'] == '000000000074.jpg':\n",
    "        print(i)\n",
    "        print(data['images'][i])\n",
    "        new_imgs.append(data['images'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['images'] = new_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['segmentation', 'num_keypoints', 'area', 'iscrowd', 'keypoints', 'image_id', 'bbox', 'category_id', 'id'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['annotations'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311\n",
      "dict_keys(['segmentation', 'num_keypoints', 'area', 'iscrowd', 'keypoints', 'image_id', 'bbox', 'category_id', 'id'])\n",
      "1347\n",
      "dict_keys(['segmentation', 'num_keypoints', 'area', 'iscrowd', 'keypoints', 'image_id', 'bbox', 'category_id', 'id'])\n",
      "3048\n",
      "dict_keys(['segmentation', 'num_keypoints', 'area', 'iscrowd', 'keypoints', 'image_id', 'bbox', 'category_id', 'id'])\n",
      "5062\n",
      "dict_keys(['segmentation', 'num_keypoints', 'area', 'iscrowd', 'keypoints', 'image_id', 'bbox', 'category_id', 'id'])\n",
      "5237\n",
      "dict_keys(['segmentation', 'num_keypoints', 'area', 'iscrowd', 'keypoints', 'image_id', 'bbox', 'category_id', 'id'])\n",
      "5273\n",
      "dict_keys(['segmentation', 'num_keypoints', 'area', 'iscrowd', 'keypoints', 'image_id', 'bbox', 'category_id', 'id'])\n",
      "116259\n",
      "dict_keys(['segmentation', 'num_keypoints', 'area', 'iscrowd', 'keypoints', 'image_id', 'bbox', 'category_id', 'id'])\n"
     ]
    }
   ],
   "source": [
    "new_anns = []\n",
    "for i in range(len(data['annotations'])):\n",
    "    if data['annotations'][i]['image_id'] == 36 or data['annotations'][i]['image_id'] == 74:\n",
    "        print(i)\n",
    "        print(data['annotations'][i].keys())\n",
    "        new_anns.append(data['annotations'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['annotations'] = new_anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "newAnnFile='{}/annotations/person_keypoints_{}-sample.json'.format(dataDir,dataType)\n",
    "with open(newAnnFile, 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "annFile = '{}/annotations/captions_{}.json'.format(dataDir,dataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(annFile)\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['info', 'licenses', 'images', 'annotations'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image_id', 'id', 'caption'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['annotations'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26035\n",
      "{'license': 2, 'file_name': '000000000074.jpg', 'coco_url': 'http://images.cocodataset.org/train2017/000000000074.jpg', 'height': 426, 'width': 640, 'date_captured': '2013-11-15 03:08:44', 'flickr_url': 'http://farm5.staticflickr.com/4087/5078192399_aaefdb5074_z.jpg', 'id': 74}\n",
      "91250\n",
      "{'license': 3, 'file_name': '000000000036.jpg', 'coco_url': 'http://images.cocodataset.org/train2017/000000000036.jpg', 'height': 640, 'width': 481, 'date_captured': '2013-11-18 06:56:10', 'flickr_url': 'http://farm8.staticflickr.com/7216/7200825264_af0f941e1a_z.jpg', 'id': 36}\n"
     ]
    }
   ],
   "source": [
    "new_imgs = []\n",
    "for i in range(len(data['images'])):\n",
    "    if data['images'][i]['file_name'] == '000000000036.jpg' or data['images'][i]['file_name'] == '000000000074.jpg':\n",
    "        print(i)\n",
    "        print(data['images'][i])\n",
    "        new_imgs.append(data['images'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['images'] = new_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5393\n",
      "{'image_id': 74, 'id': 145996, 'caption': 'A picture of a dog laying on the ground.'}\n",
      "5414\n",
      "{'image_id': 74, 'id': 146710, 'caption': 'Dog snoozing by a bike on the edge of a cobblestone street'}\n",
      "5509\n",
      "{'image_id': 74, 'id': 149398, 'caption': 'The white dog lays next to the bicycle on the sidewalk.'}\n",
      "5520\n",
      "{'image_id': 74, 'id': 149638, 'caption': 'a white dog is sleeping on a street and a bicycle'}\n",
      "5540\n",
      "{'image_id': 74, 'id': 150181, 'caption': 'A puppy rests on the street next to a bicycle.'}\n",
      "363303\n",
      "{'image_id': 36, 'id': 552549, 'caption': 'Woman in swim suit holding parasol on sunny day.'}\n",
      "363482\n",
      "{'image_id': 36, 'id': 556653, 'caption': 'A woman posing for the camera, holding a pink, open umbrella and wearing a bright, floral, ruched bathing suit, by a life guard stand with lake, green trees, and a blue sky with a few clouds behind.'}\n",
      "363495\n",
      "{'image_id': 36, 'id': 556899, 'caption': 'A woman in a floral swimsuit holds a pink umbrella.'}\n",
      "363527\n",
      "{'image_id': 36, 'id': 557547, 'caption': 'A woman with an umbrella near the sea'}\n",
      "363611\n",
      "{'image_id': 36, 'id': 559824, 'caption': 'A girl in a bathing suit with a pink umbrella.'}\n"
     ]
    }
   ],
   "source": [
    "new_anns = []\n",
    "for i in range(len(data['annotations'])):\n",
    "    if data['annotations'][i]['image_id'] == 36 or data['annotations'][i]['image_id'] == 74:\n",
    "        print(i)\n",
    "        print(data['annotations'][i])\n",
    "        new_anns.append(data['annotations'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['annotations'] = new_anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "newAnnFile='{}/annotations/captions_{}-sample.json'.format(dataDir,dataType)\n",
    "with open(newAnnFile, 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
